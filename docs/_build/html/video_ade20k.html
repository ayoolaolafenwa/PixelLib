

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Semantic segmentation of videos with PixelLib using Ade20k model &mdash; PixelLib 0.4.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Semantic segmentation of images with PixelLib using Pascalvoc model" href="Image_pascal.html" />
    <link rel="prev" title="Semantic segmentation of images with PixelLib using Ade20k model" href="image_ade20k.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> PixelLib
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="image_ade20k.html"><strong>Semantic segmentation of images with PixelLib using Ade20k model</strong></a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#"><strong>Semantic segmentation of videos with PixelLib using Ade20k model</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="#segmentation-of-live-camera-with-ade20k-model"><strong>Segmentation of live camera with Ade20k model</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="Image_pascal.html"><strong>Semantic segmentation of images with PixelLib using Pascalvoc model</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="video_pascal.html"><strong>Semantic Segmentation of videos with PixelLib using Pascalvoc model</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="video_pascal.html#segmentation-of-live-camera-with-pascalvoc-model"><strong>Segmentation of live camera with pascalvoc model</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="Image_instance.html"><strong>Instance segmentation of images with PixelLib</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="video_instance.html"><strong>Instance segmentation of videos with PixelLib</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="video_instance.html#extraction-of-objects-in-videos"><strong>Extraction of objects in videos</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="video_instance.html#segmentation-of-specific-classes-in-videos"><strong>Segmentation of  Specific Classes in Videos</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="video_instance.html#instance-segmentation-of-live-camera-with-mask-r-cnn"><strong>Instance Segmentation of Live Camera with Mask R-cnn.</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_train.html"><strong>Custom Training With PixelLib</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_inference.html"><strong>Inference With A Custom Model</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="change_image_bg.html">Image Tuning With PixelLib</a></li>
<li class="toctree-l1"><a class="reference internal" href="change_video_bg.html">Change the Background of A Video</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PixelLib</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li><strong>Semantic segmentation of videos with PixelLib using Ade20k model</strong></li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/video_ade20k.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="semantic-segmentation-of-videos-with-pixellib-using-ade20k-model">
<span id="video-ade20k"></span><h1><strong>Semantic segmentation of videos with PixelLib using Ade20k model</strong><a class="headerlink" href="#semantic-segmentation-of-videos-with-pixellib-using-ade20k-model" title="Permalink to this headline">¶</a></h1>
<p>PixelLib is implemented with Deeplabv3+ framework to perform semantic segmentation. Xception model trained on ade20k dataset is used for semantic segmentation.</p>
<p>Download the xception model from <a class="reference external" href="https://github.com/ayoolaolafenwa/PixelLib/releases/download/1.3/deeplabv3_xception65_ade20k.h5">here</a>.</p>
<p><strong>Code to implement semantic segmentation of a video with ade20k model</strong>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pixellib</span>
<span class="kn">from</span> <span class="nn">pixellib.semantic</span> <span class="kn">import</span> <span class="n">semantic_segmentation</span>

<span class="n">segment_video</span> <span class="o">=</span> <span class="n">semantic_segmentation</span><span class="p">()</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">load_ade20k_model</span><span class="p">(</span><span class="s2">&quot;deeplabv3_xception65_ade20k.h5&quot;</span><span class="p">)</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">process_video_ade20k</span><span class="p">(</span><span class="s2">&quot;video_path&quot;</span><span class="p">,</span> <span class="n">frames_per_second</span><span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="n">output_video_name</span><span class="o">=</span><span class="s2">&quot;path_to_output_video&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We shall take a look into each line of code.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pixellib</span>
<span class="kn">from</span> <span class="nn">pixellib.semantic</span> <span class="kn">import</span> <span class="n">semantic_segmentation</span>

<span class="c1">#created an instance of semantic segmentation class</span>
<span class="n">segment_image</span> <span class="o">=</span> <span class="n">semantic_segmentation</span><span class="p">()</span>
</pre></div>
</div>
<p>The class for performing semantic segmentation is imported from pixellib and we created an instance of the class.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">segment_video</span><span class="o">.</span><span class="n">load_ade20k_model</span><span class="p">(</span><span class="s2">&quot;deeplabv3_xception65_ade20k.h5&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We called the function to load the xception model trained on ade20k.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">segment_video</span><span class="o">.</span><span class="n">process_video_ade20k</span><span class="p">(</span><span class="s2">&quot;video_path&quot;</span><span class="p">,</span> <span class="n">frames_per_second</span><span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="n">output_video_name</span><span class="o">=</span><span class="s2">&quot;path_to_output_video&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>This is the line of code that performs segmentation on an image and the segmentation is done in the ade20k’s color format. This function takes in two parameters:</p>
<p><em>video_path:</em> the path to the video file we want to perform segmentation on.</p>
<p><em>frames_per_second:</em> this is parameter to set the number of frames per second for the output video file. In this case it is set to 15 i.e the saved video file will have 15 frames per second.</p>
<p><em>output_video_name:</em> the saved segmented video. The output video will be saved in your current working directory.</p>
<p><strong>sample_video</strong></p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto;">
    <iframe src="https://www.youtube.com/embed/EivIBccZURA" frameborder="0" allowfullscreen style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe>
https://www.youtube.com/watch?v=_NsELe67UxM
</div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pixellib</span>
<span class="kn">from</span> <span class="nn">pixellib.semantic</span> <span class="kn">import</span> <span class="n">semantic_segmentation</span>

<span class="n">segment_video</span> <span class="o">=</span> <span class="n">semantic_segmentation</span><span class="p">()</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">load_ade20k_model</span><span class="p">(</span><span class="s2">&quot;deeplabv3_xception65_ade20k.h5&quot;</span><span class="p">)</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">process_video_ade20k</span><span class="p">(</span><span class="s2">&quot;sample_video.mp4&quot;</span><span class="p">,</span> <span class="n">overlay</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">frames_per_second</span><span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="n">output_video_name</span><span class="o">=</span><span class="s2">&quot;output_video.mp4&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Output video</strong></p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto;">
    <iframe src="https://www.youtube.com/embed/hxczTe9U8jY" frameborder="0" allowfullscreen style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe>
https://www.youtube.com/watch?v=_NsELe67UxM
</div></div>
<div class="section" id="segmentation-of-live-camera-with-ade20k-model">
<h1><strong>Segmentation of live camera with Ade20k model</strong><a class="headerlink" href="#segmentation-of-live-camera-with-ade20k-model" title="Permalink to this headline">¶</a></h1>
<p>We can use the same model to perform semantic segmentation on camera. This can be done by few modifications to the code to process video file.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pixellib</span>
<span class="kn">from</span> <span class="nn">pixellib.semantic</span> <span class="kn">import</span> <span class="n">semantic_segmentation</span>
<span class="kn">import</span> <span class="nn">cv2</span>


<span class="n">capture</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">segment_video</span> <span class="o">=</span> <span class="n">semantic_segmentation</span><span class="p">()</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">load_ade20k_model</span><span class="p">(</span><span class="s2">&quot;deeplabv3_xception65_ade20k.h5&quot;</span><span class="p">)</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">process_camera_ade20k</span><span class="p">(</span><span class="n">capture</span><span class="p">,</span> <span class="n">overlay</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">frames_per_second</span><span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="n">output_video_name</span><span class="o">=</span><span class="s2">&quot;output_video.mp4&quot;</span><span class="p">,</span> <span class="n">show_frames</span><span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="n">frame_name</span><span class="o">=</span> <span class="s2">&quot;frame&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>
<span class="n">capture</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>We imported cv2 and included the code to capture camera frames.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">segment_video</span><span class="o">.</span><span class="n">process_camera_ade20k</span><span class="p">(</span><span class="n">capture</span><span class="p">,</span>  <span class="n">overlay</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">frames_per_second</span><span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="n">output_video_name</span><span class="o">=</span><span class="s2">&quot;output_video.mp4&quot;</span><span class="p">,</span> <span class="n">show_frames</span><span class="o">=</span> <span class="kc">True</span><span class="p">,</span><span class="n">frame_name</span><span class="o">=</span> <span class="s2">&quot;frame&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>In the code for performing segmentation, we replaced the video filepath to capture i.e we are going to process a stream camera frames instead of a video file.We added extra parameters for the purpose of showing the camera frames:</p>
<p><em>show_frames:</em> this parameter handles showing of segmented camera frames and press q to exist.
<em>frame_name:</em> this is the name given to the shown camera’s frame.</p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto;">
    <iframe src="https://www.youtube.com/embed/lOaFJpgCMB4" frameborder="0" allowfullscreen style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe>
</div><p>A demo showing the output of pixelLib’s semantic segmentation of camera’s feeds using pascal voc model.
<em>Good work! It was able to successfully segment me</em>.</p>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Image_pascal.html" class="btn btn-neutral float-right" title="Semantic segmentation of images with PixelLib using Pascalvoc model" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="image_ade20k.html" class="btn btn-neutral float-left" title="Semantic segmentation of images with PixelLib using Ade20k model" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Ayoola Olafenwa

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>