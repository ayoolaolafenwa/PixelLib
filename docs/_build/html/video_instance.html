

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Instance segmentation of videos with PixelLib &mdash; PixelLib 0.4.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Custom Training With PixelLib" href="custom_train.html" />
    <link rel="prev" title="Instance segmentation of images with PixelLib" href="Image_instance.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> PixelLib
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="image_ade20k.html"><strong>Semantic segmentation of images with PixelLib using Ade20k model</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="video_ade20k.html"><strong>Semantic segmentation of videos with PixelLib using Ade20k model</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="video_ade20k.html#segmentation-of-live-camera-with-ade20k-model"><strong>Segmentation of live camera with Ade20k model</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="Image_pascal.html"><strong>Semantic segmentation of images with PixelLib using Pascalvoc model</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="video_pascal.html"><strong>Semantic Segmentation of videos with PixelLib using Pascalvoc model</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="video_pascal.html#segmentation-of-live-camera-with-pascalvoc-model"><strong>Segmentation of live camera with pascalvoc model</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="Image_instance.html"><strong>Instance segmentation of images with PixelLib</strong></a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#"><strong>Instance segmentation of videos with PixelLib</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="#extraction-of-objects-in-videos"><strong>Extraction of objects in videos</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="#segmentation-of-specific-classes-in-videos"><strong>Segmentation of  Specific Classes in Videos</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="#instance-segmentation-of-live-camera-with-mask-r-cnn"><strong>Instance Segmentation of Live Camera with Mask R-cnn.</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_train.html"><strong>Custom Training With PixelLib</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_inference.html"><strong>Inference With A Custom Model</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="custom_inference.html#extraction-of-segmented-objects-in-videos"><strong>Extraction of Segmented Objects in Videos</strong></a></li>
<li class="toctree-l1"><a class="reference internal" href="change_image_bg.html">Image Tuning With PixelLib</a></li>
<li class="toctree-l1"><a class="reference internal" href="change_video_bg.html">Change the Background of A Video</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">PixelLib</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li><strong>Instance segmentation of videos with PixelLib</strong></li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/video_instance.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="instance-segmentation-of-videos-with-pixellib">
<span id="video-instance"></span><h1><strong>Instance segmentation of videos with PixelLib</strong><a class="headerlink" href="#instance-segmentation-of-videos-with-pixellib" title="Permalink to this headline">¶</a></h1>
<p>Instance segmentation with PixelLib is based on MaskRCNN framework.</p>
<p>Download the mask rcnn model from <a class="reference external" href="https://github.com/ayoolaolafenwa/PixelLib/releases/download/1.2/mask_rcnn_coco.h5">here</a></p>
<p><em>Code to implement instance segmentation of videos</em>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pixellib</span>
<span class="kn">from</span> <span class="nn">pixellib.instance</span> <span class="kn">import</span> <span class="n">instance_segmentation</span>

<span class="n">segment_video</span> <span class="o">=</span> <span class="n">instance_segmentation</span><span class="p">()</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;mask_rcnn_coco.h5&quot;</span><span class="p">)</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">process_video</span><span class="p">(</span><span class="s2">&quot;video_path&quot;</span><span class="p">,</span> <span class="n">frames_per_second</span><span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">output_video_name</span><span class="o">=</span><span class="s2">&quot;path_to_outputvideo&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pixellib</span>
<span class="kn">from</span> <span class="nn">pixellib.instance</span>

<span class="n">segment_video</span> <span class="o">=</span> <span class="n">instance_segmentation</span><span class="p">()</span>
</pre></div>
</div>
<p>We imported in the class for performing instance segmentation and created an instance of the class.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">segment_video</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;mask_rcnn_coco.h5&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We loaded the maskrcnn model trained on coco dataset to perform instance segmentation and it can be downloaded from here.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">segment_video</span><span class="o">.</span><span class="n">process_video</span><span class="p">(</span><span class="s2">&quot;sample_video2.mp4&quot;</span><span class="p">,</span> <span class="n">frames_per_second</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span> <span class="n">output_video_name</span> <span class="o">=</span> <span class="s2">&quot;output_video.mp4&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>We called the function  to perform segmentation on the video file.</p>
<p>It takes the following parameters:-</p>
<p><em>video_path:</em> the path to the video file we want to perform segmentation on.</p>
<p><em>frames_per_second:</em> this is parameter to set the number.of frames per second for the output video file. In this case it is set to 15 i.e the saved video file will have 15 frames per second.</p>
<p><em>output_video_name:</em> the saved segmented video. The output video will be saved in your current working directory.</p>
<p><strong>Sample video2</strong></p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto;">
    <iframe src="https://www.youtube.com/embed/EivIBccZURA" frameborder="0" allowfullscreen style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe>
https://www.youtube.com/watch?v=_NsELe67UxM
</div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pixellib</span>
<span class="kn">from</span> <span class="nn">pixellib.instance</span> <span class="kn">import</span> <span class="n">instance_segmentation</span>

<span class="n">segment_video</span> <span class="o">=</span> <span class="n">instance_segmentation</span><span class="p">()</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;mask_rcnn_coco.h5&quot;</span><span class="p">)</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">process_video</span><span class="p">(</span><span class="s2">&quot;sample_video2.mp4&quot;</span><span class="p">,</span> <span class="n">frames_per_second</span><span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="n">output_video_name</span><span class="o">=</span><span class="s2">&quot;output_video.mp4&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Output video</strong></p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto;">
    <iframe src="https://www.youtube.com/embed/yu03363mlNM" frameborder="0" allowfullscreen style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe>

</div><p>We can perform instance segmentation with object detection by setting the parameter <em>show_bboxes</em> to true.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pixellib</span>
<span class="kn">from</span> <span class="nn">pixellib.instance</span> <span class="kn">import</span> <span class="n">instance_segmentation</span>

<span class="n">segment_video</span> <span class="o">=</span> <span class="n">instance_segmentation</span><span class="p">()</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;mask_rcnn_coco.h5&quot;</span><span class="p">)</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">process_video</span><span class="p">(</span><span class="s2">&quot;sample_video2.mp4&quot;</span><span class="p">,</span> <span class="n">show_bboxes</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">frames_per_second</span><span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="n">output_video_name</span><span class="o">=</span><span class="s2">&quot;output_video.mp4&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Output video with bounding boxes</strong></p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto;">
    <iframe src="https://www.youtube.com/embed/bGPO1bCZLAo" frameborder="0" allowfullscreen style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe>

</div></div>
<div class="section" id="extraction-of-objects-in-videos">
<h1><strong>Extraction of objects in videos</strong><a class="headerlink" href="#extraction-of-objects-in-videos" title="Permalink to this headline">¶</a></h1>
<p>PixelLib supports the extraction of objects in videos and camera feeds.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">segment_video</span><span class="o">.</span><span class="n">process_video</span><span class="p">(</span><span class="s2">&quot;sample.mp4&quot;</span><span class="p">,</span> <span class="n">show_bboxes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>  <span class="n">extract_segmented_objects</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">save_extracted_objects</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">frames_per_second</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span>  <span class="n">output_video_name</span><span class="o">=</span><span class="s2">&quot;output.mp4&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>It still the same code except we  introduced new parameters in the <em>process_video</em> which are:</p>
<p><strong>extract_segmented_objects</strong>: this is the parameter that tells the function to extract the objects segmented in the image. It is set to true.</p>
<p><strong>save_extracted_objects</strong>: this is an optional parameter for saving the extracted segmented objects.</p>
<p><strong>Extracted objects from the video</strong></p>
<img alt="_images/v1.jpg" src="_images/v1.jpg" />
<img alt="_images/v2.jpg" src="_images/v2.jpg" />
<img alt="_images/v3.jpg" src="_images/v3.jpg" />
</div>
<div class="section" id="segmentation-of-specific-classes-in-videos">
<h1><strong>Segmentation of  Specific Classes in Videos</strong><a class="headerlink" href="#segmentation-of-specific-classes-in-videos" title="Permalink to this headline">¶</a></h1>
<p>The pre-trained coco model used detects 80 classes of objects. PixelLib has made it possible to filter out unused detections and detect the classes you want.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">target_classes</span> <span class="o">=</span> <span class="n">segment_video</span><span class="o">.</span><span class="n">select_target_classes</span><span class="p">(</span><span class="n">person</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">process_video</span><span class="p">(</span><span class="s2">&quot;sample.mp4&quot;</span><span class="p">,</span> <span class="n">show_bboxes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">segment_target_classes</span><span class="o">=</span> <span class="n">target_classes</span><span class="p">,</span> <span class="n">extract_segmented_objects</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">save_extracted_objects</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">frames_per_second</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span>  <span class="n">output_video_name</span><span class="o">=</span><span class="s2">&quot;output.mp4&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto;">
    <iframe src= "https://www.youtube.com/embed/WFivw1yTYfE" frameborder="0" allowfullscreen style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe>

</div><p>The target class for detection is set to person and we were able to segment only the people in the video.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">target_classes</span> <span class="o">=</span> <span class="n">segment_video</span><span class="o">.</span><span class="n">select_target_classes</span><span class="p">(</span><span class="n">car</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">process_video</span><span class="p">(</span><span class="s2">&quot;sample.mp4&quot;</span><span class="p">,</span> <span class="n">show_bboxes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">segment_target_classes</span><span class="o">=</span> <span class="n">target_classes</span><span class="p">,</span> <span class="n">extract_segmented_objects</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">save_extracted_objects</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">frames_per_second</span><span class="o">=</span> <span class="mi">5</span><span class="p">,</span>  <span class="n">output_video_name</span><span class="o">=</span><span class="s2">&quot;output.mp4&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto;">
    <iframe src= "https://www.youtube.com/embed/i9VX4r-dboM" frameborder="0" allowfullscreen style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe>

</div><p>The target class for detection is set to car and we were able to segment only the cars in the video.</p>
<p><strong>Full code for filtering classes and object Extraction</strong></p>
</div>
<div class="section" id="instance-segmentation-of-live-camera-with-mask-r-cnn">
<h1><strong>Instance Segmentation of Live Camera with Mask R-cnn.</strong><a class="headerlink" href="#instance-segmentation-of-live-camera-with-mask-r-cnn" title="Permalink to this headline">¶</a></h1>
<p>We can use the same model to perform semantic segmentation on camera. This can be done by few modifications to the code used to process video file.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pixellib</span>
<span class="kn">from</span> <span class="nn">pixellib.instance</span> <span class="kn">import</span> <span class="n">instance_segmentation</span>
<span class="kn">import</span> <span class="nn">cv2</span>


<span class="n">capture</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">segment_video</span> <span class="o">=</span> <span class="n">instance_segmentation</span><span class="p">()</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;mask_rcnn_coco.h5&quot;</span><span class="p">)</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">process_camera</span><span class="p">(</span><span class="n">capture</span><span class="p">,</span> <span class="n">frames_per_second</span><span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="n">output_video_name</span><span class="o">=</span><span class="s2">&quot;output_video.mp4&quot;</span><span class="p">,</span> <span class="n">show_frames</span><span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="n">frame_name</span><span class="o">=</span> <span class="s2">&quot;frame&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">cv2</span>
<span class="n">capture</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
<p>We imported cv2 and included the code to capture camera frames.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">segment_video</span><span class="o">.</span><span class="n">process_camera</span><span class="p">(</span><span class="n">capture</span><span class="p">,</span> <span class="n">show_bboxes</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">frames_per_second</span> <span class="o">=</span> <span class="mi">15</span><span class="p">,</span> <span class="n">output_video_name</span> <span class="o">=</span> <span class="s2">&quot;output_video.mp4&quot;</span><span class="p">,</span> <span class="n">show_frames</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="n">frame_name</span> <span class="o">=</span> <span class="s2">&quot;frame&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>In the code for performing segmentation, we replaced the video filepath to capture i.e we are going to process a stream camera frames instead of a video file.We added extra parameters for the purpose of showing the camera frames.</p>
<p><em>show_frames</em> this parameter handles showing of segmented camera frames and press q to exist.</p>
<p><em>frame_name</em> this is the name given to the shown camera’s frame.</p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; height: auto;">
    <iframe src="https://www.youtube.com/embed/HD1m-g7cOKw" frameborder="0" allowfullscreen style="position: absolute; top: 0; left: 0; width: 100%; height: 100%;"></iframe>
</div><p>A demo showing the output of pixelLib’s instance segmentation of camera’s feeds using Mask-RCNN.
<em>Good work! It was able to successfully detect me and my phone.</em></p>
<p><strong>Detection of Target Classes in Live Camera Feeds</strong></p>
<p>This is the modified code below to filter unused detections and detect a target class in a live camera feed.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pixellib</span>
<span class="kn">from</span> <span class="nn">pixellib.instance</span> <span class="kn">import</span> <span class="n">instance_segmentation</span>
<span class="kn">import</span> <span class="nn">cv2</span>


<span class="n">capture</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">segment_video</span> <span class="o">=</span> <span class="n">instance_segmentation</span><span class="p">()</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;mask_rcnn_coco.h5&quot;</span><span class="p">)</span>
<span class="n">target_classes</span> <span class="o">=</span> <span class="n">segment_video</span><span class="o">.</span><span class="n">select_target_classes</span><span class="p">(</span><span class="n">person</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">process_camera</span><span class="p">(</span><span class="n">capture</span><span class="p">,</span> <span class="n">segment_target_classes</span><span class="o">=</span><span class="n">target_classes</span><span class="p">,</span>  <span class="n">frames_per_second</span><span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">output_video_name</span><span class="o">=</span><span class="s2">&quot;output_video.mp4&quot;</span><span class="p">,</span> <span class="n">show_frames</span><span class="o">=</span> <span class="kc">True</span><span class="p">,</span><span class="n">frame_name</span><span class="o">=</span> <span class="s2">&quot;frame&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Full code for Filtering classes and object Extraction in Camera feeds</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pixellib</span>
<span class="kn">from</span> <span class="nn">pixellib.instance</span> <span class="kn">import</span> <span class="n">instance_segmentation</span>
<span class="kn">import</span> <span class="nn">cv2</span>


<span class="n">capture</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">segment_video</span> <span class="o">=</span> <span class="n">instance_segmentation</span><span class="p">()</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;mask_rcnn_coco.h5&quot;</span><span class="p">)</span>
<span class="n">target_classes</span> <span class="o">=</span> <span class="n">segment_video</span><span class="o">.</span><span class="n">select_target_classes</span><span class="p">(</span><span class="n">person</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">process_camera</span><span class="p">(</span><span class="n">capture</span><span class="p">,</span> <span class="n">segment_target_classes</span><span class="o">=</span><span class="n">target_classes</span><span class="p">,</span>  <span class="n">frames_per_second</span><span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">extract_segmented_objects</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="n">save_extracted_objects</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">output_video_name</span><span class="o">=</span><span class="s2">&quot;output_video.mp4&quot;</span><span class="p">,</span> <span class="n">show_frames</span><span class="o">=</span> <span class="kc">True</span><span class="p">,</span><span class="n">frame_name</span><span class="o">=</span> <span class="s2">&quot;frame&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Speed Adjustments for Faster Inference</strong></p>
<p>PixelLib now supports the ability to adjust the speed of detection according to a user’s needs. The inference speed with a minimal reduction in the accuracy of detection. There are three main parameters that control the speed of detection.</p>
<p>1 <strong>average</strong></p>
<p>2 <strong>fast</strong></p>
<p>3 <strong>rapid</strong></p>
<p>By default the detection speed is about 1 second for a processing a single image using Nvidia GeForce 1650.</p>
<p><strong>Using Average Detection Mode</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pixellib</span>
<span class="kn">from</span> <span class="nn">pixellib.instance</span> <span class="kn">import</span> <span class="n">instance_segmentation</span>
<span class="kn">import</span> <span class="nn">cv2</span>


<span class="n">capture</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">segment_video</span> <span class="o">=</span> <span class="n">instance_segmentation</span><span class="p">(</span><span class="n">infer_speed</span> <span class="o">=</span> <span class="s2">&quot;average&quot;</span><span class="p">)</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;mask_rcnn_coco.h5&quot;</span><span class="p">)</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">process_camera</span><span class="p">(</span><span class="n">capture</span><span class="p">,</span> <span class="n">frames_per_second</span><span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">output_video_name</span><span class="o">=</span><span class="s2">&quot;output_video.mp4&quot;</span><span class="p">,</span> <span class="n">show_frames</span><span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="n">frame_name</span><span class="o">=</span> <span class="s2">&quot;frame&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>In the modified code above within the class <em>instance_segmentation</em> we introduced a new parameter <strong>infer_speed</strong> which determines the speed of detection and it was set to <strong>average</strong>. The average value reduces the detection to half of its original speed, the detection speed would become <em>0.5</em> seconds for processing a single image.</p>
<p><strong>Using fast Detection  Mode</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pixellib</span>
<span class="kn">from</span> <span class="nn">pixellib.instance</span> <span class="kn">import</span> <span class="n">instance_segmentation</span>
<span class="kn">import</span> <span class="nn">cv2</span>


<span class="n">capture</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">segment_video</span> <span class="o">=</span> <span class="n">instance_segmentation</span><span class="p">(</span><span class="n">infer_speed</span> <span class="o">=</span> <span class="s2">&quot;fast&quot;</span><span class="p">)</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;mask_rcnn_coco.h5&quot;</span><span class="p">)</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">process_camera</span><span class="p">(</span><span class="n">capture</span><span class="p">,</span> <span class="n">frames_per_second</span><span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">output_video_name</span><span class="o">=</span><span class="s2">&quot;output_video.mp4&quot;</span><span class="p">,</span> <span class="n">show_frames</span><span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="n">frame_name</span><span class="o">=</span> <span class="s2">&quot;frame&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>In the code above we replaced the <strong>infer_speed</strong>  value to <strong>fast</strong> and the speed of detection is about <em>0.35</em> seconds for processing a single image.</p>
<p><strong>Using rapid Detection Mode</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pixellib</span>
<span class="kn">from</span> <span class="nn">pixellib.instance</span> <span class="kn">import</span> <span class="n">instance_segmentation</span>
<span class="kn">import</span> <span class="nn">cv2</span>


<span class="n">capture</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">VideoCapture</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">segment_video</span> <span class="o">=</span> <span class="n">instance_segmentation</span><span class="p">(</span><span class="n">infer_speed</span> <span class="o">=</span> <span class="s2">&quot;rapid&quot;</span><span class="p">)</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;mask_rcnn_coco.h5&quot;</span><span class="p">)</span>
<span class="n">segment_video</span><span class="o">.</span><span class="n">process_camera</span><span class="p">(</span><span class="n">capture</span><span class="p">,</span> <span class="n">frames_per_second</span><span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">output_video_name</span><span class="o">=</span><span class="s2">&quot;output_video.mp4&quot;</span><span class="p">,</span> <span class="n">show_frames</span><span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="n">frame_name</span><span class="o">=</span> <span class="s2">&quot;frame&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>In the code above we replaced the <strong>infer_speed</strong>  value to <strong>rapid</strong> the fastest the detection mode. The speed of detection  becomes
<em>0.25</em> seconds for processing a single image.
The rapid detection speed mode achieves 4fps.</p>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="custom_train.html" class="btn btn-neutral float-right" title="Custom Training With PixelLib" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Image_instance.html" class="btn btn-neutral float-left" title="Instance segmentation of images with PixelLib" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Ayoola Olafenwa

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>